{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "# Read the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# Access the API token from the configuration file\n",
    "huggingfacehub_api_token = config.get('huggingface', 'api_token')\n",
    "# Set your API Key from OpenAI\n",
    "openai_api_key = config.get('openai', 'api_key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the best is coming.\n",
      "\n",
      "Oh thank you for your kind words. I am a bit worried but I have faith that things will work out as they are meant to.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Define the LLM\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=openai_api_key)\n",
    "\n",
    "# Predict the words following the text in question\n",
    "question = 'dont worry , be sure that'\n",
    "output = llm.invoke(question)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To retain learning effectively, you can try the following strategies:\\n\\n1. **Regular Review**: Review the material periodically to reinforce your memory.\\n2. **Practice Retrieval**: Test yourself on the information you've learned to strengthen your memory.\\n3. **Teach Others**: Explaining concepts to someone else can help solidify your understanding.\\n4. **Use Multiple Modalities**: Engage with the material in different ways, such as reading, writing, listening, and discussing.\\n5. **Apply the Knowledge**: Use what you've learned in real-life situations to make it more memorable.\\n6. **Stay Engaged**: Maintain your interest in the subject by finding ways to connect it to your personal interests or goals.\\n7. **Get Enough Sleep**: Quality sleep is crucial for memory consolidation.\\n8. **Stay Organized**: Keep your notes and study materials well-organized for easy reference.\\n\\nBy incorporating these strategies into your learning routine, you can improve your retention and understanding of the material.\", response_metadata={'token_usage': {'completion_tokens': 198, 'prompt_tokens': 27, 'total_tokens': 225}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-3d0a6f2b-cbb2-4d01-82ab-1a2a5ba5fb3a-0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define an OpenAI chat model\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)\t\t\n",
    "\n",
    "# Create a chat prompt template\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"Respond to question: {question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Insert a question into the template and call the model\n",
    "full_prompt = prompt_template.format_messages(question='How can I retain learning?')\n",
    "llm.invoke(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\SL\\.cache\\huggingface\\token\n",
      "Login successful\n",
      ". It's the only way to ensure they last longer and look better for longer. (If you're in a hurry, you can simply go to a shoe store and find the right shoe for your needs and budget.)\n",
      "The Big Daddy shoes are designed to keep your feet comfortable, and they're made with the finest materials.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "\n",
    "# Define the LLM\n",
    "llm = HuggingFaceEndpoint(repo_id='tiiuae/falcon-7b-instruct', huggingfacehub_api_token=huggingfacehub_api_token)\n",
    "\n",
    "# Predict the words following the text in question\n",
    "question = 'Whatever you do, take care of your shoes'\n",
    "output = llm.invoke(question)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\SL\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "{'question': 'How does LangChain make LLM application development easier?', 'text': '\\nLangChain simplifies LLM application development by providing a platform to streamline the process of creating, testing, and deploying legal applications. Our platform offers a variety of pre-built modules, templates, and APIs to help developers save time and resources. Additionally, we offer a range of developer tools and services, including continuous integration and automated testing, to ensure applications are of the highest quality and meet regulatory standards.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "\n",
    "# Define the LLM\n",
    "llm = HuggingFaceEndpoint(repo_id='tiiuae/falcon-7b-instruct', huggingfacehub_api_token=huggingfacehub_api_token)\n",
    "\n",
    "question = \"How does LangChain make LLM application development easier?\"\n",
    "\n",
    "# Create a prompt template from the template string\n",
    "template = \"You are an artificial intelligence assistant, answer the question. {question}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# Create a chain to integrate the prompt template and LLM\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print(llm_chain.invoke(question))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
